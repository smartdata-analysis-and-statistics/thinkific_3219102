---
title: "Comparative Effectiveness of Treatments for COPD: A Network Meta-Analysis Example"
author: "Thomas Debray"
format:
  html:
    toc: true
    number-sections: true
execute:
  message: false
  warning: false
bibliography: 'bibliography.bib'
---


## Overview
This vignette reproduces the main analyses discussed in the book chapter "Principles of meta-analysis and indirect treatment comparisons" [@debray_principles_2025].

Here, we focus on a case study evaluating the comparative effectiveness of maintenance inhaled therapies for chronic obstructive pulmonary disease (COPD).

The example is based on the systematic review by Baker et al. [@baker_pharmacologic_2009], which identified 39 randomized controlled trials including 28,232 patients. These trials compared long-acting β₂-agonists (LABAs), tiotropium (TIO), inhaled corticosteroids (ICS), and combination ICS–LABA therapies with respect to exacerbation risk. The corresponding treatment network contains multiple closed loops, enabling both direct and indirect treatment comparisons. Unlike the COVID-19 example, this network provides an opportunity to assess local inconsistency across overlapping comparisons and to explore sources of heterogeneity and bias within a richer evidence structure.

## Data Source

Trials were identified through a systematic literature search of the following databases: MEDLINE (1950 -- October 2007), EMBASE (1990 -- October 2007), CINAHL (1982 -- October 2007), the Cochrane Central Register of Controlled Trials (third quarter 2007), as well as Web of Science (1994 -- October 2007).

Inclusion criteria were:

* Randomized and controlled design (placebo or active comparator).
* Study population consisting of patients with chronic obstructive pulmonary disease (COPD).
* Evaluation of at least one of the following COPD drug classes:
  * Inhaled corticosteroids (ICS)
  * Tiotropium (TIO)
  * Long-acting β₂-agonists (LABAs)
  * Combination ICS–LABA therapy
* Reporting of outcomes related to COPD exacerbation frequency or mortality.
	
Data are available from the R package `netmeta`:

```{r}
#| message: false
library(netmeta)
data(Baker2009)
```

```{r}
#| echo: false
library(kableExtra)
kable(head(Baker2009))
```

The primary outcome was the occurrence of one or more episodes of COPD exacerbation, recorded as a binary variable (yes/no).
The network compares five single-agent treatments—fluticasone, budesonide, salmeterol, formoterol, and tiotropium—and two combination therapies (fluticasone + salmeterol and budesonide + formoterol) against placebo.
Importantly, the original authors treated the combination therapies as distinct interventions rather than decomposing them into their individual components.

## Setting up the Network

We first define the network of interventions and visualize the geometry of available evidence.

```{r}
#| echo: true
#| message: false
#| warning: false
library(multinma)
library(ggplot2)

net <- set_agd_arm(data = Baker2009,
                   study = study,
                   trt = treatment,
                   r = exac,
                   n = total)

plot(net, weight_edges = TRUE, weight_nodes = TRUE)  +
    theme(legend.position = "none")
```


## Random-Effects Network Meta-Analysis

We first fit a random-effects model using the binomial likelihood with logit link. We use vague priors for heterogeneity and relative effects.

```{r}
#| echo: true
#| message: false
#| warning: false
library(dplyr)

nma_consistency <- nma(
  net,
  trt_effects = "random",
  prior_trt = normal(scale = 10),
  prior_het = half_normal(scale = 5),
  refresh = 0
)

# Extract DIC
dic_consistency <- dic(nma_consistency)

# Extract tau (posterior mean)
tau_consistency <- summary(nma_consistency)$summary %>%
  as.data.frame() %>%
  filter(parameter == "tau") %>%
  pull(mean)
```

We find the following estimate for tau, the between-study standard deviation: `r round(tau_consistency, 3)`. The DIC for this model is `r round(dic_consistency$dic, 1)`.

To complement the relative treatment effects, we summarize the probability that each treatment ranks among the best options in reducing COPD exacerbations.
Cumulative rank probabilities provide a visual summary of the likelihood that a given treatment occupies each possible rank position, with higher curves indicating a higher probability of superior performance.
@fig-rankprobs displays these probabilities for all treatments included in the network meta-analysis, using placebo as the reference.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-rankprobs
#| fig-cap: "Cumulative rank probabilities for treatments in COPD. Each curve represents the probability that a treatment ranks among the top *k* options (lower ranks indicate greater efficacy). Placebo is shown as the reference."
db_rankprobs <- posterior_rank_probs(nma_consistency, 
                                     lower_better = TRUE, 
                                     cumulative = TRUE)
plot(db_rankprobs)
```


## Assessing Inconsistency
To assess local inconsistency, we apply the node-splitting approach to each comparison with both direct and indirect evidence.

```{r}
#| echo: true
#| message: false
#| warning: false
nma_inconsistency <- nma(
  net,
  consistency = "ume",
  trt_effects = "random",
  prior_trt = normal(scale = 5),
  prior_het = half_normal(scale = 2.5),
  refresh = 0
)

# Extract DIC
dic_inconsistency <- dic(nma_inconsistency)

# Extract tau (posterior mean)
tau_inconsistency <- summary(nma_inconsistency)$summary %>%
  as.data.frame() %>%
  filter(parameter == "tau") %>%
  pull(mean)
```

We estimated the between-study heterogeneity parameter, $\tau$, to be `r round(tau_inconsistency, 3)`. For the same model, the Deviance Information Criterion (DIC) was `r round(dic_inconsistency$dic, 1)`, providing an overall measure of model fit that balances goodness-of-fit and model complexity.

To further explore model fit and potential inconsistency, we compared the residual deviance contributions from the consistency and UME models. Each point in the plot below represents the contribution of a study–treatment arm to the overall residual deviance. Points lying below the diagonal indicate observations that are better explained under the UME (inconsistent) model, suggesting potential sources of inconsistency.

```{r}
#| echo: true
#| message: false
#| warning: false
#| label: fig-resdev
#| fig-cap: "Comparison of study-level residual deviance contributions between the consistency and UME models."
# Extract residual deviance contributions from both models
resdev_cons <- dic_consistency$pointwise$agd_arm %>%
  select(.study, .trt, resdev_cons = resdev)
resdev_ume <- dic_inconsistency$pointwise$agd_arm %>%
  select(.study, .trt, resdev_ume = resdev)

# Merge by study and treatment
resdev_joined <- full_join(resdev_cons, resdev_ume, 
                           by = c(".study", ".trt"))

# Plot comparison
ggplot(resdev_joined, aes(x = resdev_cons, y = resdev_ume)) +
  geom_abline(intercept = 0, slope = 1, linetype = "solid", color = "grey50") +
  geom_point(size = 2) +
  coord_equal() +
  theme_minimal(base_size = 12) +
  labs(
    x = "Residual Deviance (Consistency model)",
    y = "Residual Deviance (UME model)"
  )
```

Finally, we can identify data points with substantial differences in residual deviance between the two models:

```{r}
#| echo: true
#| message: false
#| warning: false

resdev_joined %>%
  filter(abs(resdev_cons - resdev_ume) > 1)
```

The results indicate that most studies fit both models similarly, with only the van Noord (2005) study -- specifically the Tiotropium and Formoterol arms -- showing improved fit under the UME model. This pattern points to possible local inconsistency associated with that study.

